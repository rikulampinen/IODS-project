# Chapter 2: Regression and model validation

### Data wrangling and regression analysis 

#### *Work of week 45 (4.11. - 10.11.2019)*

***
## 1. Data wrangling

**4.11.2019**: Started to work through the DataCamp exercises offered by the IODS course and was able to finish  

* R Short and Sweet   
* R Helsinki Open Data Science courses      
    

**5.11.2019**: Start to work on R script for data wrangling and regression analysis  

* Wrote the script for data wrangling and was able to finish that part (all tests on the script worked)
  
Now follows a discription through my work progress.
 
### 1.1. Read the dataframe  

##### **Script of the data read (reading the dataframe from the website)**
  
```{r, readdata1, echo=TRUE, results='hide', message=FALSE, warning=FALSE}
# Read the data file ----
learning2014 <- read.table(file = 
                "https://www.mv.helsinki.fi/home/kvehkala/JYTmooc/JYTOPKYS3-data.txt", 
                sep = "\t", header = TRUE)                          
                # read the data file and assign it to the object "learning2014"

# Explore the read data ----

head(learning2014) # see the top of the dataset with the first 6 observations
str(learning2014) # check the structure of the dataset --> --> (observations = rows and variables = columns)
dim(learning2014) # check the table dimensions --> (observations = rows and variables = columns)
```
  
The dataset consists of 183 observations (rows) in 60 variables (columns). 
  
If you want to check the data also with some diagrams, you can use for example following plots:  

```
# Structure of some the data in plot or in a histogram (here the variable Points from)
library(ggplot2)
qplot(Attitude, Points, data = learning2014)
hist(learning2014$Points)
```
  
  
What follows now is the data wrangling. We have to summarize variables of deep, surface and strategic learning approaches and calclulate the mean value of the summarized variables. Other variables stay (gender, Attitude, Points), only the column names are changed.
  
### 1.2. Perform the data wrangling  

##### **Script for data wrangling**

I decided to do the data wrangling into a new R object (a dataframe) which I named "lrn14_analysis". This dataframe will later be used for the data analyses.  
Here I used a more complicated way to do the data wrangling, in the meeting on Wednesday, 6.11. a way with the pipe operator %>% was presented.  
  
```{r, wrangledata, echo=TRUE, results='hide', message=FALSE, warning=FALSE}
# Create an analysis dataset: "lrn14_analysis" ----

# Create an analysis dataset with the variables gender, age, attitude, deep, stra, surf and points 
# (by combining questions in the learning2014 data)

library(dplyr) # load the package for data wrangling

keep_columns <- c("gender","Age","Attitude","Points") # these are the data columns which need to be kept
lrn14_analysis <- select(learning2014, one_of(keep_columns))  # assin a new object and select kept columns
colnames(lrn14_analysis) <- c("gender", "age", "attitude", "points") # change of the kept column names

# define questions (observations from variables) acc. instructions
deep_q <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")  # deep questions
surf_q <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32") # surface questions
stra_q <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28") # strategic questions

# Select the combined variables (columns) & scale the observations (mean) and add it to the analysis dataframe
deep <- select(learning2014, one_of(deep_q))
lrn14_analysis$deep <- round(rowMeans(deep, na.rm = TRUE), digits = 2) # values are rounded to 2 digits

surf <- select(learning2014, one_of(surf_q))
lrn14_analysis$surf <- round(rowMeans(surf,na.rm = TRUE), digits = 2)

stra <- select(learning2014, one_of(stra_q))
lrn14_analysis$stra <- round(rowMeans(stra, na.rm = TRUE), digits = 2)

# devide the number of the attitude column by 10 (its a sum of 10 questions)
lrn14_analysis$attitude <- lrn14_analysis$attitude / 10

# Exclude observations where the exam points variable is zero. 
lrn14_analysis <- filter(lrn14_analysis, points > 0)
```
  
The new dataframe was created. Now the structure is checked.  
```{r, structure, echo=TRUE, results='markup', message=FALSE, warning=FALSE}
# Check the analysis dataset
str(lrn14_analysis)
dim(lrn14_analysis)
```
  
The data consists now of 7 variables (columns) and 166 observations. The object name is "lrn14_analysis".  
  
***
### 1.3. Safe the updated dataframe as a .txt table or .csv table  

First the the working directory is set and then I save the dataframe with `write.table()` and the `write.csv()`functions.

```
# Set the working directory to IODS project folder ---- 
setwd("~/IODS-project") # set the wd to the IODS folder
```
```
# safe the analysis dataset to the "data" folder ----

write.table(lrn14_analysis, 
      file = "C:/Users/richla/OneDrive/1 C - R-Folder/11-IODS-course/IODS-project/data/lrn14_analysis_table.txt",
      sep = "\t", col.names = TRUE, row.names = TRUE)

write.csv(lrn14_analysis, 
      file = "C:/Users/richla/OneDrive/1 C - R-Folder/11-IODS-course/IODS-project/data/lrn14_analysis_table.csv",
      row.names = FALSE)
```
  
Afterwards I check if the tables can be read by R using the `read.table()` and `read.csv()` function plus the `%>%`operator piping to the `head()` function showing the first 6 observations of the dataframes.  

```{r, checktables,structure, echo=TRUE, results='markup', message=FALSE, warning=FALSE}
# check if the table can be read ----
read.table(file = 
             "C:/Users/richla/OneDrive/1 C - R-Folder/11-IODS-course/IODS-project/data/lrn14_analysis_table.txt") %>% head()

read.csv(file = 
           "C:/Users/richla/OneDrive/1 C - R-Folder/11-IODS-course/IODS-project/data/lrn14_analysis_table.csv")  %>%head()
```  
  

***   
## 2. Analysis

The work on the analysis script and documentation started on 6.11.2019.    

### 2.1. Reading the data    
Read the dataset table from my data folder and checked the dataframe structure and dimensions.  

``` 
# Set the working directory
setwd("~/IODS-project/data") # set work directory
```
```{r, dataread2, echo=TRUE, results='markdown', message=FALSE, warning=FALSE }
# Read the data file ----
lrn14_analysis <- 
read.table(file = "C:/Users/richla/OneDrive/1 C - R-Folder/11-IODS-course/IODS-project/data/lrn14_analysis_table.txt", stringsAsFactors = TRUE) 

lrn14_analysis %>% str() # read the data table and check the structure

```
  
When I read the data table I set the "stringsAsFactor" agument (in the read.table function) to `TRUE`. So the observations in the gender column "F" and "M" will become factors - here 1 & 2. The dataframe includes 166 observations (the rows) in 7 variables (the columns).  

### 2.2. Graphical overview and data summary     
The data we analyise consists of a survey from students relating their learning approaches.
The data includes the students' gender, age, exam points and the global attitude towards statistics (consisting of a sum of 10 questions related to students attitude towards statistics, each measured on the Likert scale (1-5). The attitude value was divided by 10 in the data wrangling part to show the value in the 1-5 scale. 

For a graphical overview of the dataset I used the `ggpairs()` function which results in several plots and correlations of the observations between the different variables.   
  
```
library(ggplot2) 
library(GGally) # to show the graph these packages need to be loaded

ov_lrn14_2 <- ggpairs(lrn14_analysis, mapping = aes(col = gender), title = "Graphical overview of lrn14_analysis", 
                      lower = list(combo = wrap("facethist", bins = 20)), 
                      upper = list(continuous = wrap("cor", size = 2.8)))

ov_lrn14_2 # show the graph
```
![](C:/Users/richla/OneDrive/1 C - R-Folder/11-IODS-course/IODS-project/data/OV_plot_lrn14.png)
  
  
The overview plot shows the data distribution of all observations of each variable with a histogramm, Q-plots (point diagrams) and the line graphs. The data colours represent the different gender of the students of the data frame. Here female students are shown in redish colour and male students in turquise colour.  
In the upper right part of the overview graph the data correlations (all observations of one variable correlating to the observations of another varibable) is shown. These results give a first hint which variable might show a significant regression analysis result.
  
  
```
# Save the overview plot

ggsave("OV_plot_lrn14.png", 
       plot = ov_lrn14_2, path = "~/IODS-project/data/", scale = 1, dpi = 300) 
# the graph is saved as .png file in my data folder
```  

Additionally a data summary table of the lrn14_analysis dataset was created.
  
```{r, sumtable, echo=TRUE, results='markdown', message=FALSE, warning=FALSE}
# Summary table of the lrn14_analysis data ----

Sum_table <- summary(lrn14_analysis)
Sum_table
```
  

***
### 2.3. Regression models  
#### 2.3.1. Simple regression model of **point ~ attitude**
  
I was testing different simple regression models with the exam points as dependent variable (y) using function `lm()`.
```
# Simple regressions ----

# regression with gender variable
gen_lm <- lm(points ~ gender, data = lrn14_analysis)
summary(gen_lm) # not significant

# regression with age variable
age_lm <- lm(points ~ age, data = lrn14_analysis)
summary(age_lm) # not significant
```  
  
These regression analysis did not result in significant outcomes. Next the I performed the regression analysis of points ~ attitude. This had following outcome:
  
``` {r, regression1sum, echo=TRUE, results='markdown', message=FALSE, warning=FALSE}
# attitude
att_lm <- lm(points ~ attitude, data = lrn14_analysis)
att_lm_res <- summary(att_lm)
att_lm_res

knitr::kable(att_lm_res$coefficients, digits=3, caption="Regression coefficients point ~ attitude")
```


  
Here the diagnostic plots of the regression model **points ~ attitude**:
  
``` {r, regression1plot, echo=TRUE, results='markdown', message=FALSE, warning=FALSE}
plot(att_lm, which = c(1,2,5))
```
  
  
#####  Regression model **point ~ attitude** interpretation:  

Significant outcome was shown in the simple regression analysis of point ~ attitude.  

The summary of the regression model shows that the estimate increase of points by a value of 1 of attitude is 3.525.
The p-value of 4.12e-09 *** represents that as asignificant result (it's pretty much 0). So the students' attitude (relating statistics) has a significant influence in the exam points outcome. So depending on the attitude the student has a higher number of points or a lower one. But the intercept shows a value of 11.63 - so even with zero attitude a student would still reach a level of 11 points at an exam.  
The multiple R-squared represents the correlation coefficient. It is the square root of R-squared (the coefficient of determination). The multiple R-squared explains how strong the linear relationship is, which would be strongest with a value of 1 and weakest with a value of 0 (no relationship). Here the value is 0.1906, so not a very strong relationship, but it has an effect.  

The diagnostic plots consist of a "Residual vs. Fitted plot which is used to check the linearity (or non-linearity) of the observations, eventual variance errors (observations which concentrate in a certain direction) and you can also check if there are possible outliers in your dataset.  
The resulting plots of our points ~ attitude model show a good linearity and a good variance. The observations are nicely distributed over the base line and you cannot see any direction were the points might show a variance difference. There are also three outliers (145, 56, 35), but these are not disturbing the analysis and don't have to be removed since they are still centered in the overall data point distribution.  
The Normal Q-Q plot helps us to check the data distribution of our dataset (normal distributed or exponential). Our datapoints are nicely distributed over the line and are normal distributed. That means that our analysis does not need any transformed data points before any further statistical analysis (for example logarithm or square root transformation).  
The Residual vs. Leverage plot helps us to identify if there are observations which might have a high impact on a statistical model. So the observations in our case show very low leverage and even the points which are further away from the others show low leverage and so cannot be considered as outliers.

Additionally here is a plot representing points vs. attitude with the regressions line. For me it makes it easier to understand the whole thing when the data is shown is a graph.
  
```{r, qplot_points_attitude, echo=TRUE, results='markdown', message=FALSE, warning=FALSE}
library(ggplot2)
qplot(attitude, points, data = lrn14_analysis) + geom_smooth(method = "lm")
```
  
In the graph someone can check if the estimate increase of 3.525 per one unit of attitude is shown by the regression line.  
  
***    

#### 2.3.2. Multiple regression model of **point ~ attitude + stra**  
  
Here I'm checking the linear regression of points ~ attitude and strategic learning approach outcome - I want to know if the strategic learning approach has a relationship to the exampoints of the students.

```{r, regression2sum, echo=TRUE, results='markdown', message=FALSE, warning=FALSE}
# points ~ attitude + stra ----

att_st_lm <- lm(points ~ attitude + stra, data = lrn14_analysis)
att_st_lm_res <- summary(att_st_lm)
att_st_lm_res

knitr::kable(att_st_lm_res$coefficients, digits=3, caption="Regression coefficients point ~ attitude + stra")
```
  
Here the diagnostic plots of the regression model **points ~ attitude + stra**:  

``` {r, regression2plot, echo=TRUE, results='markdown', message=FALSE, warning=FALSE}

plot(att_st_lm, which = c(1,2,5))
```
  
  
#####  Regression model **point ~ attitude + stra** interpretation:    

In this multiple regression I wanted to see if the strategic learning approach shows an influence on the amount of exampoints a student can reach. The outcome shows that the strategic learning approach has some influence but not a very strong one. Also the p-value of 0.08 shows that the significance of the influence is not very strong.
The multiple R-squared is a bit higher compared to points ~ attitude regression model so we have a little higher correlations if we put the strategic learning approach into account.  
The diagnostic plots show more or less the same results as in the regression model point ~ attitude. Data is normal distributed and no outliers are significantly disturbing the analysis.  

***

#### 2.3.3. Multiple regression model of **point ~ deep + surf + stra**   

In the third regression model I put points vs. deep, surface and strategic learning approach into account. Does the combination of deep, surface and strategic learning approach have an influence in the exampoints of students.

```{r, regression3sum, echo=TRUE, results='markdown', message=FALSE, warning=FALSE}
# points ~ + deep + surf + stra ----

de_su_st_lm <- lm(points ~ deep + surf + stra, data = lrn14_analysis)
de_su_st_lm_res <- summary(de_su_st_lm)

de_su_st_lm_res

knitr::kable(de_su_st_lm_res$coefficients, digits=3, caption="Regression coefficients point ~ deep + surf + stra")
```


Here the diagnostic plots of the regression model **points ~ + deep + surf + stra**:  

``` {r, regression3plot, echo=TRUE, results='markdown', message=FALSE, warning=FALSE}

plot(de_su_st_lm, which = c(1,2,5))
```
    
#####  Regression model **point ~ deep + surf + stra** interpretation:  
  
The outcome of this regression model shows that with a minor significance (0.0762) the surface learning approach has some indluence to the exam outcomes of students. Checking the estimate for surf show a negative value of -1.63 which means that students with a surface learning approach tent to have 1.6 points less as a test result with a increased surface learning approach value of 1. The deep learning approach seem to have no influence at all in the amount of points students reach at the exams and the stratetic approach has a non-significant positive influence.  
The multiple R-squared of 0.04 is very low and explains that there is more or less no correlation between these variables and the exampoints from the students.

Here I put the three variables into a `qplot()` to show the relationsships of the learning approaches and the exampoints.  

```{r, qplot_points_surf, echo=TRUE, results='markdown', message=FALSE, warning=FALSE}
library(ggplot2)
par(mfrow = c(2,2))
qplot(deep, points, data = lrn14_analysis) + geom_smooth(method = "lm") + ggtitle("Points vs. deep learning approach")
qplot(surf, points, data = lrn14_analysis) + geom_smooth(method = "lm")+ ggtitle("Points vs. surface learning approach")
qplot(stra, points, data = lrn14_analysis) + geom_smooth(method = "lm")+ ggtitle("Points vs. strategic learning approach")
```
  
So, this was a trial to analyse the dataset with simple and multiple regression models. I hope the interpretations are easily understood and the diary structure is not confusing you.  
I had fun preparing this first statistics and graph chapter and I'm looking forward to learn more...  
  
***

